import pandas as pd
import numpy as np


train = pd.read_csv("./data/train.csv")
test = pd.read_csv("./data/test.csv")


train = train.drop( columns = {"Id"})








numeric = [ var for var in train.columns if train[var].dtype == "int64" or "float64"]
categorical = [ var for var in train.columns if train[var].dtype == "O"]


numeric





date_var = ["YearBuilt", "YearRemodAdd", "MoSold", "YrSold","GarageYrBlt"]
categorical.extend(["MSSubClass", "OverallQual", "OverallCond"])
numeric = list(set(numeric) - set(categorical) - set(date_var))
len(numeric)


print(len(categorical))
print(len(date_var))











train[numeric].isnull().sum()





train = train.dropna(subset = numeric,ignore_index = True)


train[date_var].isnull().sum()


train[categorical].isnull().sum()





train = train.dropna(subset=date_var, ignore_index=True)





# Electrical had 1 missing value which can't signify no existence. so that is dropped and other values are imputed as None.

train = train.dropna( subset =["Electrical"], ignore_index = True)
train = train.fillna("None")
train.isnull().sum()





from sklearn.preprocessing import FunctionTransformer
from sklearn.preprocessing import MinMaxScaler





unit_numeric = ["FullBath", "GarageCars", "BsmtHalfBath", "BsmtFullBath", "KitchenAbvGr", "Fireplaces", "TotRmsAbvGrd", "HalfBath", "BedroomAbvGr"]
numeric = list(set(numeric) - set(unit_numeric))
len(numeric)


log_transformer = FunctionTransformer(np.log1p, inverse_func = np.expm1) 


min_max_scaler = MinMaxScaler()





from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import OneHotEncoder








rating_1 = ["None", "No", "Mn", "Av", "Gd"]
rating_2 = ["None", "Unf", "LwQ", "Rec", "BLQ", "ALQ", "GLQ"]
rating_3 = ["None","Po","Fa","TA","Gd","Ex"]

rating_3_cat = list()
rating_2_cat = list()
rating_1_cat = list()

for i in categorical:
    if set(train[i].value_counts().index.tolist()).issubset(set(rating_3)):
        print(i)
        rating_3_cat.append(i)

for i in categorical:
    if set(train[i].value_counts().index.tolist()).issubset(set(rating_2)):
        print(i)
        rating_2_cat.append(i)

for i in categorical:
    if set(train[i].value_counts().index.tolist()).issubset(set(rating_1)):
        print(i)
        rating_1_cat.append(i)


rating_1_encoder = OrdinalEncoder(categories = [rating_1 for i in rating_1_cat])
rating_2_encoder = OrdinalEncoder(categories = [rating_2 for i in rating_2_cat])
rating_3_encoder = OrdinalEncoder(categories = [rating_3 for i in rating_3_cat])


unrelative_cat = list((((set(categorical) - set(rating_1_cat)) - set(rating_2_cat)) - set(rating_3_cat))) 


unrelative_encoder = OneHotEncoder()





train[date_var].info()


train["GarageYrBlt"] = train["GarageYrBlt"].astype("int64")


X_train = train.drop( columns = {"SalePrice"})
y_train = train["SalePrice"]
numeric.remove("SalePrice")


# y_train = log_transformer.transform(y_train)





from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer


num_pipeline = Pipeline([
    ("Logarithm", log_transformer),
    ("Scaling", min_max_scaler),
])
rating_1_pipeline = Pipeline([
    ("rating1", rating_1_encoder)
])
rating_2_pipeline = Pipeline([
    ("rating2", rating_2_encoder)
])
rating_3_pipeline = Pipeline([
    ("rating3", rating_3_encoder)
])
unrelative_cat_pipeline = Pipeline([
    ("onehot", unrelative_encoder)
])


preprocessing = ColumnTransformer([
     ("numeric", num_pipeline, numeric),
    ("ordinal1", rating_1_pipeline, rating_1_cat),
    ("ordinal2",rating_2_pipeline, rating_2_cat),
    ("ordinal3",rating_3_pipeline, rating_3_cat),
    ("unrelative", unrelative_cat_pipeline, unrelative_cat),
], remainder = "passthrough")


pipeline = Pipeline(steps=[('preprocessor', preprocessing)])


X_train_transformed = pipeline.fit_transform(X_train)
print(type(X_train_transformed))


X_train_transformed.toarray().shape





y_train


from sklearn.linear_model import LinearRegression
from sklearn.metrics import root_mean_squared_error

linear = LinearRegression()
linear.fit(X_train_transformed, y_train)
y_pred = linear.predict(X_train_transformed)

# y_pred_real = log_transformer.inverse_transform(y_pred)
# y_train_real = log_transformer.inverse_transform(y_train)
# root_mean_squared_error(y_train_real, y_pred_real)

root_mean_squared_error(y_train, y_pred)


print(y_train_real.min())
print(y_train_real.max())





from sklearn.tree import DecisionTreeRegressor

decision_tree = DecisionTreeRegressor()
decision_tree.fit(X_train_transformed,y_train)
y_pred = decision_tree.predict(X_train_transformed)

# y_train_real = log_transformer.inverse_transform(y_train)
# y_pred_real = log_transformer.inverse_transform(y_pred)
root_mean_squared_error(y_train, y_pred)





from sklearn.ensemble import RandomForestRegressor

random_forest = RandomForestRegressor()
random_forest.fit(X_train_transformed, y_train)
y_pred = random_forest.predict(X_train_transformed)

# y_train_real = log_transformer.inverse_transform(y_train)
# y_pred_real = log_transformer.inverse_transform(y_pred)

root_mean_squared_error(y_train, y_pred)








from sklearn.model_selection import cross_val_score

linear_rmse = -cross_val_score(linear, X_train_transformed, y_train, scoring="neg_root_mean_squared_error", cv = 10)
decision_rmse = -cross_val_score(decision_tree, X_train_transformed, y_train, scoring="neg_root_mean_squared_error", cv = 10)
random_rmse = -cross_val_score(random_forest, X_train_transformed, y_train, scoring="neg_root_mean_squared_error", cv = 10)

print(linear_rmse)
print(decision_rmse)
print(random_rmse)


pd.Series(linear_rmse).describe()


pd.Series(decision_rmse).describe()


pd.Series(random_rmse).describe()



